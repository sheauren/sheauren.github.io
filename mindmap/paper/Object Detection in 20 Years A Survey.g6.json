{
    "id": "root",
    "isroot": true,
    "title": "Object Detection in 20 Years A Survey",
    "collapsed": false,
    "children": [
        {
            "id": "line_0",
            "title": "A Road Map of Object Detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_1",
                    "title": "Milestones: Traditional Detectors",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_2",
                            "title": "Viola-Jones(VJ) detector features:",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_3",
                                    "title": "integral image",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_4",
                                            "title": "Haar wavelet is used in VJ detector as the feature representation of an image",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_5",
                                            "title": "The integral image makes the computational complexity of each window in VJ detectorindependent of its window size.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_6",
                                    "title": "feature selection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_7",
                                            "title": "Instead of using a set of manually selected Haar basis filters",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_8",
                                            "title": "the authors used Adaboost algorithm [32] to select a small set of features that are mostlyhelpful for face detection from a huge set of random features pools (about 180k-dimensional).",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_9",
                                    "title": "detection cascades",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_10",
                                            "title": "A multi-stage detection paradigm(a.k.a. the \"detection cascades\") was introduced in VJ detector to reduce its computational overhead by spending less computations on background windows but more on face targets.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_11",
                            "title": "HOG Detector features:",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_12",
                                    "title": "improvement of the scale-invariant feature transform and shape contexts",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_13",
                                    "title": "To balance the feature invariance(including translation, scale, illumination, etc) and the nonlinearity (on discriminating different objects cat-egories)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_14",
                                    "title": "designed to be computed on a dense grid of uniformly spaced cells and use overlapping local contrast normalization (on \"blocks\") for improving accuracy",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_15",
                            "title": "Deformable Part-based Model (DPM) features:",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_16",
                                    "title": "divide and conquer",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_17",
                                    "title": "A typical DPM detector consists of a root-filter and anumber of part-filters.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_18",
                                    "title": "Instead of manually specifying theconfigurations of the part filters",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_19",
                                    "title": "aweakly supervised learning method is developed in DPM where all configurations of part filters can be learned automatically as latent variables.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_20",
                    "title": "Milestones: CNN based Two-stage Detectors",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_21",
                            "title": "RCNN",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_22",
                                    "title": "It starts with the extraction of a set of object proposals (object candidate boxes)by selective search",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_23",
                                    "title": "Then each proposal is rescaled to a fixed size image and fed into a CNN model trained onImageNet (say, AlexNet [40]) to extract features.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_24",
                                    "title": "linear SVM classifiers are used to predict the presence of anobject within each region and to recognize object categories.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_25",
                            "title": "Spatial Pyramid PoolingNetworks (SPPNet)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_26",
                                    "title": "introduction of a Spatial Pyramid Pooling (SPP) layer, which enables a CNN to generate a fixed-length representation regardless of the size of image/region of interest without rescaling it.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_27",
                                    "title": "the training is still multi-stage, second, SPPNet only fine-tunes its fully connected layers while simply ignores all previous layers",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_28",
                            "title": "Fast RCNN",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_29",
                                    "title": "enables us to simultaneously train adetector and a bounding box regressor under the same network configurations.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_30",
                            "title": "Faster RCNN",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_31",
                                    "title": "RCNN is the first end-to-end, and the first near-realtime deep learning detector",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_32",
                                    "title": "The main contribution of Faster-RCNN is the introduction of Region Proposal Network (RPN) that enables nearly cost-free region proposals.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_33",
                            "title": "Feature Pyramid Networks",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_34",
                                    "title": "a top-down architecture with lateral connections is developed inFPN for building high-level semantics at all scales.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_35",
                    "title": "Milestones: CNN based One-stage Detectors",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_36",
                            "title": "You Only Look Once (YOLO)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_37",
                                    "title": "This network divides the image into regionsand predicts bounding boxes and probabilities for eachregion simultaneously.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_38",
                                    "title": "YOLO suffers from a drop of the localization accuracy com-pared with two-stage detectors, especially for some smallobjects.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_39",
                            "title": "Single Shot MultiBox Detector (SSD)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_40",
                                    "title": "introduction of the multi-referenceand multi-resolution detection techniques",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_41",
                                    "title": "improves the detectionaccuracy of a one-stage detector, especially for some small objects.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_42",
                            "title": "RetinaNet",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_43",
                                    "title": "a new loss function named \"focal loss\" has been introduced in RetinaNet by reshaping the standard crossentropy loss so that detector will put more focus on hard,misclassified examples during training.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_44",
            "title": "Dataset",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_45",
                    "title": "PASCAL VOC Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_46",
                            "title": "The PASCAL Visual Object Classes (VOC) Challenges",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_47",
                                    "title": "VOC07",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_48",
                                            "title": "5k tr. images + 12k annotated objects",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_49",
                                    "title": "VOC12",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_50",
                                            "title": "11k tr. images + 27k annotated objects.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_51",
                                    "title": "20 classes",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_52",
                                    "title": "Person: person; Animal: bird, cat, cow,dog, horse, sheep; Vehicle: aeroplane, bicycle, boat, bus, car,motor-bike, train; Indoor: bottle, chair, dining table, pottedplant, sofa, tv/monitor).",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_53",
                                    "title": "ImageNet Large Scale Visual Recognition Challenge",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_54",
                    "title": "ILSVRC",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_55",
                            "title": "The ImageNet Large Scale Visual Recognition Challenge(ILSVRC)",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_56",
                            "title": "using ImageNet images",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_57",
                            "title": "ILSVRC-14",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_58",
                                    "title": "517k images and 534k annotated objects.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_59",
                    "title": "MS COCO",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_60",
                            "title": "MS-COCO-17",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_61",
                                    "title": "164k images and 897k annotated objects from 80 categories",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_62",
                            "title": "MS-COCO contains more small objects (whose area is smaller than 1% of the image)and more densely located objects than VOC and ILSVRC.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_63",
                    "title": "Open Images",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_64",
                            "title": "Open Images Detection (OID) challenge",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_65",
                                    "title": "1. the standard object detection,",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_66",
                                    "title": "2. the visual relationship detection which detects paired objects inparticular relations.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_67",
                                    "title": "1,910k images with 15,440k annotated boundingboxes on 600 object categories.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_68",
                    "title": "Datasets of Other Detection Tasks",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_69",
                            "title": "detection applications in specific areas",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_70",
                            "title": "pedestrian detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_71",
                                    "title": "MIT Ped.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_72",
                                    "title": "INRIA",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_73",
                                    "title": "Caltech",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_74",
                                    "title": "KITTI",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_75",
                                    "title": "CityPersons",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_76",
                                    "title": "EuroCity",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_77",
                            "title": "face detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_78",
                                    "title": "FDDB",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_79",
                                    "title": "AFLW",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_80",
                                    "title": "IJB",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_81",
                                    "title": "WiderFace",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_82",
                                    "title": "UFDD",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_83",
                                    "title": "WildestFaces",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_84",
                            "title": "textdetection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_85",
                                    "title": "ICDAR",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_86",
                                    "title": "STV",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_87",
                                    "title": "MSRA-TD500",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_88",
                                    "title": "IIIT5K",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_89",
                                    "title": "Syn90k",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_90",
                                    "title": "COCOText",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_91",
                            "title": "traffic sign/light detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_92",
                                    "title": "TLR",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_93",
                                    "title": "LISA",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_94",
                                    "title": "GTSDB",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_95",
                                    "title": "BelgianTSD",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_96",
                                    "title": "TT100K",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_97",
                                    "title": "BSTL",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_98",
                            "title": "remote sensing",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_99",
                                    "title": "TAS",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_100",
                                    "title": "OIRDS",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_101",
                                    "title": "DLR3K",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_102",
                                    "title": "UCAS-AOD",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_103",
                                    "title": "VeDAI",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_104",
                                    "title": "NWPU-VHR10",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_105",
                                    "title": "LEVIR",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_106",
                                    "title": "DOTA",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_107",
                                    "title": "xView",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_108",
                            "title": "target detection",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_109",
            "title": "Metrics",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_110",
                    "title": "How can we evaluate the effectiveness of an object detector?",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_111",
                    "title": "different answers at different time",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_112",
                    "title": "pedestriandetection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_113",
                            "title": "miss rate vs. false positives per-window(FPPW)",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_114",
                            "title": "Caltech pedestrian detection benchmark",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_115",
                            "title": "false positives per-image (FPPI)",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_116",
                    "title": "average presicion",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_117",
                            "title": "most frequently used evaluation forobject detection is \"Average Precision (AP)\"",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_118",
                            "title": "the mean AP (mAP)averaged over all object categories is usually used as thefinal metric of performance.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_119",
                    "title": "measure the object localization accuracy",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_120",
                            "title": "the Intersection over Union (IoU)",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_121",
                            "title": "the IoU between the predicted box andthe ground truth box is greater than a predefined threshold(0.5)",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_122",
                            "title": "IoU thresholds between 0.5 (coarse localization) and 0.95 (perfect localization).",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_123",
                            "title": "the Open Images dataset consideringthe group-of boxes and the non-exhaustive image-level category hierarchies.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_124",
                            "title": "localization recall precision",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_125",
            "title": "Technical Evolution in Object Detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_126",
                    "title": "Early Time's Dark Knowledge",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_127",
                            "title": "designed based on low-level and mid-level vision",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_128",
                                    "title": "Components, shapes and edges",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_129",
                                    "title": "Recognition-by-components",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_130",
                                    "title": "a measurement ofsimilarity between the object components, shapes and contours, including Distance Transforms, Shape Contexts, and Edgelet, etc.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_131",
                            "title": "Machine learning based detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_132",
                                    "title": "statistical models of appearance(before 1998)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_133",
                                            "title": "Eigenfaces",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_134",
                                    "title": "wavelet feature representations (1998-2005)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_135",
                                            "title": "transforming an imagefrom pixels to a set of wavelet coefficients",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_136",
                                            "title": "Haar wavelets basis learned by a VJ detector",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_137",
                                    "title": "gradient-based representations (2005-2012)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_138",
                                            "title": "Early time's CNN for object detection",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_139",
                                            "title": "\"shared-weight replicated neural network\"",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_140",
                                            "title": "\"space displacement network\"",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_141",
                    "title": "Technical Evolution of Multi-Scale Detection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_142",
                            "title": "feature pyramids and sliding windows (before 2014)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_143",
                                    "title": "VJ detector",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_144",
                                    "title": "mixture model",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_145",
                                    "title": "feature pyramid",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_146",
                                    "title": "exemplar-based detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_147",
                            "title": "detection with object proposals (2010-2015)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_148",
                                    "title": "HOG detector, DPM, and even the Overfeatdetector",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_149",
                                    "title": "the detection of \"various aspectratios\" was not considered at that time.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_150",
                                    "title": "Object proposals refer to a group of class-agnostic candidate boxes that likely to contain any objects.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_151",
                                            "title": "An object proposal detection algorithm should meetthe following three requirements:",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_152",
                                                    "title": "1. high recall rate",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_153",
                                                    "title": "2. high localization accuracy",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_154",
                                                    "title": "3. basis of the first two requirements, to improve precision and reduce processingtime.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        },
                                        {
                                            "id": "line_155",
                                            "title": "Modern proposal detection methods",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_156",
                                                    "title": "1. segmentation grouping approaches",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_157",
                                                    "title": "2. window scoring approaches",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_158",
                                                    "title": "3. neural network based approaches",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_159",
                            "title": "deep regression(2013-2016)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_160",
                                    "title": "directly predict the co-ordinates of a bounding box based on the deep learningfeatures",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_161",
                            "title": "multi-reference/-resolution detection (after 2015/after 2016)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_162",
                                    "title": "Multi-reference detection is the most popular frameworkfor multi-scale object detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_163",
                                    "title": "pre-define a set of reference boxes (a.k.a. anchor boxes)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_164",
                                            "title": "A typical loss of each predefined anchor box consists of two parts:",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_165",
                                                    "title": "1.a cross-entropy loss for category recognitionand",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_166",
                                                    "title": "2.an L1/L2 regression loss for object localization.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "id": "line_167",
                                    "title": "Multi-resolution detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_168",
                                            "title": "from a feature pyramid during its forward propagation",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_169",
                    "title": "Technical Evolution of Bounding Box Regression",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_170",
                            "title": "Without BB regression (before 2008)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_171",
                                    "title": "usually directly consider the sliding window as the detection result.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_172",
                                    "title": "build very dense pyramid and slide thedetector densely on each location.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_173",
                            "title": "From BB to BB (2008-2013)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_174",
                                    "title": "the BB regression at that time usually acted as a post-processing block, thusit is optional",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_175",
                                    "title": "predict a bounding box based on the complete configuration of an object hypothesis andformulate this process as a linear least-squares regression problem",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_176",
                            "title": "From features to BB (after 2013)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_177",
                                    "title": "BB regression no longer serves as an individual post-processing block but has been integrated with the detector and trainedin an end-to-end fashion.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_178",
                                    "title": "BB regression has evolved to predicting BB directly based on CNN fea-tures.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_179",
                    "title": "Technical Evolution of Context Priming",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_180",
                            "title": "detection with local context",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_181",
                                    "title": "Local context refers to the visual information in the area that surrounds the object to detect.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_182",
                                    "title": "deep learning based detectorscan also be improved with local context by simply enlargingthe networks' receptive field or the size of object proposals",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_183",
                            "title": "detection with global context",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_184",
                                    "title": "Global context exploits scene configuration as an additional source of information for object detection.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_185",
                                    "title": "For modern deeplearning based detectors, there are two methods to integrateglobal context.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_186",
                                            "title": "The first way is to take advantage of large receptive field orglobal pooling operation of a CNN feature",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_187",
                                            "title": "The secondway is to think of the global context as a kind of sequential information and to learn it with the recurrent neural net-works",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_188",
                            "title": "context interactives",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_189",
                                    "title": "Context interactive refers to the piece of information that conveys by the interactions of visual elements, such as the constraints and dependencies.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_190",
                                    "title": "Some recent improvements can be grouped into two categories",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_191",
                                            "title": "the first one is to explore the relationship between individual objects",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_192",
                                            "title": "the second one is toexplore modeling the dependencies between objects and scenes",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_193",
                    "title": "Technical Evolution of Non-Maximum Suppression",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_194",
                            "title": "Non-maximum suppression (NMS) is an important group oftechniques in object detection.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_195",
                            "title": "the non-maximumsuppression is herein used as a post-processing step toremove the replicated bounding boxes and obtain the finaldetection result",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_196",
                            "title": "NMS has been graduallydeveloped into the following three groups of methods:",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_197",
                                    "title": "1. greedy selection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_198",
                                            "title": "for a set of overlapped detections, the bounding box with the maximum detectionscore is selected while its neighboring boxes are removed according to a predefined overlap threshold (say, 0.5).",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_199",
                                            "title": "it does not suppress false positives.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_200",
                                            "title": "the greedyselection still performs as the strongest baseline for today'sobject detection.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_201",
                                    "title": "2. bounding box aggregation",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_202",
                                            "title": "the idea of combining or clustering multiple overlapped bounding boxes into one final detection.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_203",
                                            "title": "The advantage of this type of method is that it takes full consideration of object relationships and their spatial layout.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_204",
                                    "title": "3. learning to NMS",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_205",
                                            "title": "The main idea of such group of methods is to thinkof NMS as a filter to re-score all raw detections and to trainthe NMS as part of a network in an end-to-end fashion.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_206",
                    "title": "Technical Evolution of Hard Negative Mining",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_207",
                            "title": "The training of an object detector is essentially an imbalanced data learning problem.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_208",
                            "title": "Hard negative mining (HNM) aims to deal with theproblem of imbalanced data during training.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_209",
                            "title": "Bootstrap",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_210",
                                    "title": "Bootstrap in object detection refers to a group of training techniques in which the training starts with a small partof background samples and then iteratively add new missclassified backgrounds during the training process",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_211",
                            "title": "HNM in deep learning based detectors",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_212",
                                    "title": "balance the weights between the positive and negative windows.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_213",
                                    "title": "the weight-balancing cannot completely solvethe imbalanced data problem",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_214",
                                    "title": "only the gradients of a very small part of samples will be back-propagated",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_215",
                                    "title": "In RefineDet ,an \"anchor refinement module\" is designed to filter easy negatives",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_216",
                                    "title": "An alternative improvementis to design new loss functions",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_217",
                                    "title": "reshapingthe standard cross entropy loss so that it will put more focuson hard, misclassified examples",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_218",
            "title": "SPEED-UP OFDETECTION",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_219",
            "title": "1. speed up of detection pipeline",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_220",
            "title": "2. speed up of detection engine",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_221",
            "title": "3. speed up of numerical computation",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_222",
            "title": "Feature Map Shared Computation",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_223",
                    "title": "the feature extraction usually dominates the amountof computation",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_224",
                    "title": "a sliding window based detector, the computational redundancy starts from both positions and scales",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_225",
            "title": "Spatial Computational Redundancy and Speed Up",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_226",
                    "title": "The most commonly used idea to reduce the spatial computational redundancy is feature map shared computation",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_227",
                    "title": "The idea of feature map shared computation has alsobeen extensively used in convolutional based detectors",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_228",
            "title": "Scale Computational Redundancy and Speed Up",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_229",
                    "title": "directly scale the features rather than the images",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_230",
                    "title": "building \"detector pyramid\" is another way to avoid scale computational redundancy",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_231",
            "title": "Speed up of Classifiers",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_232",
                    "title": "Detec-tion with nonlinear classifiers such as kernel SVM suggestshigher accuracy, but at the same time brings high computational overhead.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_233",
                    "title": "the \"model approximation\" is most commonly used.",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_234",
                            "title": "Since the decision boundary of a classical kernel SVM can only be determined by a small set of its training samples.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_235",
                            "title": "Reduced Set Vectors is an approximation method for kernel SVM, which aims to obtain an equivalent decisionboundary in terms of a small number of synthetic vectors.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_236",
                            "title": "its decision boundary to a piece-wiselinear form so as to achieve a constant inference time",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_237",
                            "title": "The kernel method can also be accelerated with the sparseencoding methods",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_238",
            "title": "Cascaded Detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_239",
                    "title": "to filter out most of the simple backgroundwindows using simple calculations, then to process thosemore difficult windows with complex ones.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_240",
            "title": "Network Pruning and Quantification",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_241",
                    "title": "\"Network pruning\" and \"network quantification\" are two commonly used techniques to speed up a CNN model",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_242",
                            "title": "pruning the network structure or weight to reduce its size and the latter one refers to reducing the code-length of activations or weights.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_243",
                    "title": "Network Pruning",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_244",
                            "title": "optimal brain damage",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_245",
                            "title": "compress the parameters of a multi-layer perceptron network",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_246",
                            "title": "the loss function of a network is approximated by taking the second-order derivatives so that to remove some unimportant weights.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_247",
                            "title": "the network pruning methods in recent years usually take an iterative training and pruning process",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_248",
                                    "title": "to remove only a smallgroup of unimportant weights after each stage of training",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_249",
                                    "title": "to repeat those operations",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_250",
                                    "title": "As traditional network pruning simply removes unimportant weights, which may result in some sparse connectivity patterns in a convolutional filter",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_251",
                                    "title": "A simple solution is to remove thewhole filters instead of the independent weights",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_252",
                    "title": "Network Quantification",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_253",
                            "title": "accelerate a networkby quantifying its activations or weights to binary variablessay, 0/1) so that the floating-point operation is convertedto AND, OR, NOT logical operations.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_254",
                            "title": "etwork binariza-tion can significantly speed up computations and reducethe network's storage so that it can be much easier to bedeployed on mobile devices.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_255",
                            "title": "One possible implementationof the above ideas is to approximate the convolution bybinary variables with the least squares method",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_256",
                            "title": "some researchers have further developed GPUacceleration libraries for binarized computation, which ob-tained more significant acceleration results",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_257",
                    "title": "Network Distillation",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_258",
                            "title": "Network distillation is a general framework to compress theknowledge of a large network (\u201cteacher net\u201d) into a smallone (\u201cstudent net\u201d) [",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_259",
                            "title": "Onestraight forward approach of this idea is to use a teacher netto instruct the training of a (light-weight) student net so thatthe latter can be used for speed up detection",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_260",
                            "title": "Anotherapproach is to make transform of the candidate regions soas to minimize the features distance between the student netand teacher net.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_261",
            "title": "Lightweight Network Design",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_262",
                    "title": "The last group of methods to speed up a CNN based detector is to directly design a lightweight network instead ofusing off-the-shelf detection engines.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_263",
                    "title": "factorizing convolutions",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_264",
                            "title": "First group of methods is to factorize a large convolution filter into a set of small ones in their spatial dimension",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_265",
                                    "title": "one canfactorize a 7x7 filter into three 3x3 filters",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_266",
                                    "title": "or factorize a k\u00d7k filter into a k\u00d71 filterand a 1\u00d7k filter",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_267",
                            "title": "The second group of methods is to factorize a large group of convolutions into two small groups in their channel dimension",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_268",
                    "title": "group convolution",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_269",
                            "title": "Group convolution aims to reduce the number of parameters in a convolution layer by dividing the feature channelsinto many different groups, and then convolve on each group independently.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_270",
                    "title": "depth-wise separable convolution",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_271",
                            "title": "It can be viewed as a special case of thegroup convolution when the number of groups is set equalto the number of channels",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_272",
                    "title": "bottle-neck design",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_273",
                            "title": "A bottleneck layer in a neural network contains few nodescompared to the previous layers. It can be used to learningefficient data encodings of the input with reduced dimensionality.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_274",
                    "title": "neural architecture search",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_275",
                            "title": "there has been significant interest in designing network architectures automatically by neural ar-chitecture search (NAS) instead of relying heavily on expert experience and knowledge.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_276",
            "title": "Numerical Acceleration",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_277",
                    "title": "The last group of methods to speed up a CNN based detector is to directly design a lightweight network instead ofusing off-the-shelf detection engines.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_278",
                    "title": "speed up with the integral image",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_279",
                            "title": "The integral image is an important method in image processing",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_280",
                                    "title": "sparse signal",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_281",
                                    "title": "color histogram",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_282",
                                    "title": "gradient histogram",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_283",
                                    "title": "integral HOG maps",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_284",
                                    "title": "Integral Channel Features (ICF)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_285",
                    "title": "speed up in the frequency domain",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_286",
                            "title": "As the detection of a linear detectorcan be viewed as the window-wise inner product between the feature map and detector's weights",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_287",
                                    "title": "Fourier transform",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_288",
                                    "title": "Fast Fourier Transform (FFT)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_289",
                                    "title": "Inverse Fast Fourier Transform (IFFT)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_290",
                    "title": "vector quantization",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_291",
                            "title": "The Vector Quantization (VQ) is a classical quantization method in signal processing that aims to approximate thedistribution of a large group of data by a small set of prototype vectors.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_292",
                    "title": "reduced rank approximation",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_293",
                            "title": "The reduced rank approximation is a method to accelerate matrix multiplications.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_294",
            "title": "RECENT ADVANCES IN OBJECT DETECTION",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_295",
            "title": "Detection with Better Engines",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_296",
                    "title": "Alexnet",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_297",
                            "title": "an eight-layer deep network",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_298",
                            "title": "AlexNet famously won the2012 ImageNet LSVRC-2012 competition by a large margin",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_299",
                    "title": "VGG",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_300",
                            "title": "VGG increased the model'sdepth to 16-19 layers and used very small (3x3) convolutionfilters instead of 5x5 and 7x7 those were previously used inAlexNet.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_301",
                    "title": "Inception(GoogLeNet)",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_302",
                            "title": "The main contribution of theInception family is the introduction of factorizing convolu-tion and batch normalization.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_303",
                    "title": "ResNet(The Deep Residual Networks)",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_304",
                            "title": "ResNet aims to ease the training of networks by reformulating its layers aslearning residual functions with reference to the layer inputs.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_305",
                    "title": "DenseNet",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_306",
                            "title": "The authors embracedthis observation and introduced a densely connected block,which connects each layer to every other layer in a feed-forward fashion",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_307",
                    "title": "SENet(Squeeze and Excitation Networks )",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_308",
                            "title": "Itsmain contribution is the integration of global pooling andshuffling to learn channel-wise importance of the featuremap.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_309",
                    "title": "Object detectors with new engines",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_310",
                            "title": "STDN, DSOD,TinyDSOD, and Pelee choose DenseNet as their detection engine.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_311",
                            "title": "The Mask RCNN, as the state of the art model for instance segmentation, applied the next generation of ResNet: ResNeXt as its detection engine.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_312",
                            "title": "Xception, an improved version of Incepion, has also been used in detectors such as MobileNet and LightHead RCNN",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_313",
            "title": "Detection with Better Features",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_314",
                    "title": "The quality of feature representations is critical for objectdetection.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_315",
                    "title": "feature fusion",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_316",
                            "title": "Invariance and equivariance are two important propertiesin image feature representations.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_317",
                            "title": "Classification desires invariant feature representations",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_318",
                            "title": "Object localization desiresequivariant representations",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_319",
                            "title": "object detection consists oftwo sub-tasks of object recognition and localization, it is cru-cial for a detector to learn both invariance and equivarianceat the same time.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_320",
                            "title": "features in deeper layers will have stronger invariance but less equivariance.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_321",
                            "title": "features in shallower layers is not conducive to learning semantics, but it helps object localization",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_322",
                            "title": "the integration of deep and shallow features ina CNN model helps improve both invariance and equivariance.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_323",
                    "title": "Feature Fusion in Different Ways",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_324",
                            "title": "processing flow",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_325",
                                    "title": "bottom-up fusion",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_326",
                                            "title": "Bottom-up fusionfeeds forward shallow features to deeper layers via skip connections",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_327",
                                    "title": "top-down fusion",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_328",
                                            "title": "top-down fusion feeds back the features of deeper layers into the shallowerones",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_329",
                                    "title": "Apart from these methods, there are more complex approaches proposed recently, e.g., weaving features across different layers",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_330",
                                    "title": "fractional strided convolution (a.k.a. transpose convolution) is an-other recent popular way to resize the feature maps and adjust the number of channels.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_331",
                            "title": "element-wise operation",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_332",
                                    "title": "From a local point of view, feature fusion can be consid-ered as the element-wise operation between different featuremaps.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_333",
                                    "title": "There are three groups of methods:",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_334",
                                    "title": "element-wise sum",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_335",
                                    "title": "element-wise product",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_336",
                                    "title": "concatenation",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_337",
                    "title": "learning high-resolution features with large receptive fields",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_338",
                            "title": "The receptive field and feature resolution are two important characteristics of a CNN based detector",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_339",
                            "title": "the latter one corresponds to the down-sampling rate betweenthe input and the feature map.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_340",
                            "title": "lower the feature resolutionis, the harder will be to detect small objects",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_341",
                                    "title": "remove pooling layer",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_342",
                                    "title": "reduce the convolution down-sampling rate.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_343",
                                    "title": "but narrow a detector's \"sight\", may result in the miss detection of some large objects.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_344",
                                    "title": "A piratical method to increase both of the receptive field and feature resolution at the same time is to introduce dilated convolution (a.k.a. atrous convolution, or convolution with holes)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_345",
                                            "title": "expand the convolution filter and use sparse parameters",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_346",
                                    "title": "Dilated convolution has now been widelyused in object detection and proves tobe effective for improved accuracy without any additionalparameters and computational cost",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_347",
            "title": "Beyond Sliding Window",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_348",
                    "title": "Detection as sub-region search",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_349",
                            "title": "One recent method is to think of detection as a path planning process that starts from initial grids and finally converges to the desired groundtruth boxes",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_350",
                            "title": "Another method is to think of detectionas an iterative updating process to refine the corners of apredicted bounding box",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_351",
                    "title": "Detection as key points localization",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_352",
                            "title": "As any object in an image can be uniquely determined by its upper left corner and lower right corner of the ground truth box, the detection task, therefore, can beequivalently framed as a pair-wise key points localization problem.",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_353",
                                    "title": "predict a heat-map for the corners",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_354",
            "title": "Improvements of Localization",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_355",
                    "title": "Bounding Box Refinement",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_356",
                            "title": "The most intuitive way to improve localization accuracyis bounding box refinement, which can be considered asa post-processing of the detection results",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_357",
                            "title": "the \"iterative bounding box refinement\" has been in-troduced recently by iteratively feeding the detection resultsinto a BB regressor until the prediction converges to a correctlocation and size.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_358",
                    "title": "designing new loss functions for accurate localization.",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_359",
                            "title": "object localization is consideredas a coordinate regression problem",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_360",
                            "title": "there are two drawbacks of this paradigm.",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_361",
                                    "title": "the regression lossfunction does not correspond to the final evaluation oflocalization.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_362",
                                    "title": "traditional bounding box regression methoddoes not provide the confidence of localization.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_363",
                                            "title": "When thereare multiple BB\u2019s overlapping with each other, this may leadto failure in non-maximum suppression",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_364",
                            "title": "The most intuitive design is to directly use IoU as the localization loss function",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_365",
                            "title": "Some otherresearchers have further proposed an IoU-guided NMS to improve localization in both training and detection stages",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_366",
                            "title": "to improve localization under a probabilistic inference framework",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_367",
                            "title": "Different from the previous methods that directly predictthe box coordinates, this method predicts the probabilitydistribution of a bounding box location",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_368",
            "title": "Learning with Segmentation",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_369",
                    "title": "recent researches suggestobject detection can be improved by learning with semanticsegmentation.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_370",
                    "title": "Why Segmentation Improves Detection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_371",
                            "title": "There are three reasons why the semantic segmentationimproves object detection",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_372",
                            "title": "Segmentation helps category recognition",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_373",
                                    "title": "As the feature of semantic segmentation tasks well captures the boundary of an object, segmentation may be helpful for category recognition.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_374",
                            "title": "Segmentation helps accurate localization",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_375",
                                    "title": "The ground-truth bounding box of an object is determined by its well-defined boundary.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_376",
                                    "title": "As objectboundaries can be well encoded in semantic segmentation features, learning with segmentation would be helpful for accurate object localization.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_377",
                            "title": "Segmentation can be embedded as context",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_378",
                                    "title": "Objects in daily life are surrounded by different back-grounds, such as the sky, water, grass, etc, and all theseelements constitute the context of an object.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_379",
                    "title": "How Segmentation Improves Detection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_380",
                            "title": "Learning with enriched features",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_381",
                                    "title": "The simplest way is to think of the segmentation net-work as a fixed feature extractor and to integrate it into a de-tection framework as additional features [",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_382",
                            "title": "Learning with multi-task loss functions",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_383",
                                    "title": "to train this model with multi-task loss functions (segmenta-tion loss + detection loss)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_384",
                                    "title": "the segmen-tation brunch will be removed at the inference stage",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_385",
            "title": "Robust Detection of Rotation and Scale Changes",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_386",
                    "title": "features learned by CNN arenot invariant to rotation and large degree of scale changes",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_387",
                    "title": "Rotation Robust Detection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_388",
                            "title": "solution to this problem is data augmentation so that anobject in any orientation can be well covered by the aug-mented data",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_389",
                            "title": "Another solution is to train independent detectors for every orientation",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_390",
                            "title": "Rotation invariant loss functions",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_391",
                                    "title": "Some recent workshave introduced a constraint on the original detection lossfunction so that to make the features of rotated objects unchanged",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_392",
                            "title": "Rotation calibration",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_393",
                                    "title": "make geometric transformations of the objects candidates",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_394",
                                    "title": "This will be especially helpful for multi-stage detectors, where the correlation at early stages will benefit the subsequent detections.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_395",
                                            "title": "The representative of this ideais Spatial Transformer Networks (STN)",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_396",
                            "title": "Rotation RoI Pooling",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_397",
                                    "title": "A recent improvement is to mesh the grids in polarcoordinates so that the features could be robust to therotation changes",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_398",
                    "title": "Scale Robust Detection",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_399",
                            "title": "Scale adaptive training",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_400",
                                    "title": "Most of the modern detectors re-scale the input imageto a fixed size and back propagate the loss of the objectsin all scales",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_401",
                                            "title": "scale imbalance",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_402",
                                    "title": "Building an image pyramid during detection could alleviate this problem but not fundamentally",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_403",
                                    "title": "A recent improvement is Scale Normalization for Image Pyramids(SNIP), which builds image pyramids at both of training and detection stages and only backpropagates the loss of some selected scales.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_404",
                                    "title": "a more efficient training strategy: SNIP with Efficient Resampling (SNIPER),to crop and re-scale an image to a set of sub-regions so that to benefit from large batch training",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_405",
                            "title": "Scale adaptive detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_406",
                                    "title": "Most of the modern detectors use the fixed configura-tions for detecting objects of different sizes.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_407",
                                    "title": "we need to carefullydefine the size of anchors",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_408",
                                            "title": "A drawback of doing this isthe configurations cannot be adaptive to unexpected scalechanges.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_409",
                                    "title": "To improve the detection of small objects,",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_410",
                                            "title": "\"adaptive zoom-in\" techniques are proposed in some recent detectors to adaptively enlarge the small objects into the \"larger ones\"",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_411",
                                    "title": "learning to predict the scale distribution of objects in an image",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_412",
                                    "title": "then adaptively rescaling the image according to the distribution",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_413",
            "title": "Training from Scratch",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_414",
            "title": "Most deep learning based detectors are first pre-trained onlarge scale datasets, say ImageNet, and then fine-tuned onspecific detection tasks.",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_415",
                    "title": "do we really need topre-training a detector on ImageNet?",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_416",
                            "title": "The first limitation is the divergence between ImageNet classification and object detection",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_417",
                            "title": "he second limitation is the domain mismatch.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_418",
            "title": "some researchers have tried to train an object detector from scratch",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_419",
                    "title": "using standard models trained fromrandom initialization",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_420",
                            "title": "he sole exception of increasing the number of training iterations so the randomly initialized models may converg",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_421",
                            "title": "that ImageNet pre-training mayspeed up convergence, but does not necessarily provideregularization or improve final detection accuracy",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_422",
            "title": "Adversarial Training",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_423",
                    "title": "GAN has been used to enhance the detection on small objects by narrowing the representations between small and large ones",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_424",
                    "title": "To improve the detection of occluded objects, one recent idea is to generate occlusion masks by using adversarial training",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_425",
                    "title": "adversarial attack",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_426",
                            "title": "which aims to study how to attack a detector with adver-sarial examples,has drawn increasing attention recently.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_427",
            "title": "Weakly Supervised Object Detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_428",
                    "title": "The training of a modern object detector usually requiresa large amount of manually labeled data, while the label-ing process is time-consuming, expensive, and inefficient.",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_429",
                            "title": "Weakly Supervised Object Detection (WSOD) aims to solve this problem by training a detector with only image level annotations instead of bounding boxes.",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        },
                        {
                            "id": "line_430",
                            "title": "multi-instance learning has been used for WSOD, Multi-instance learning is a group of supervised learning method ,each containing many instances",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_431",
                    "title": "Class activation mapping is another recently group of methods for WSOD",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_432",
                            "title": "Class activation mapping shedlight on how to enable a CNN to have localization ability despite being trained on image level labels",
                            "background-color": "#e82ad2",
                            "collapsed": true
                        }
                    ]
                },
                {
                    "id": "line_433",
                    "title": "some other researchers considered the WSOD as a proposal ranking process by selecting the most informative regions and then training these regions with image-level annotation",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_434",
                    "title": "simple method for WSOD is to mask out different parts of the image.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_436",
            "title": "Application",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_437",
            "title": "pedestrian detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_438",
                    "title": "autonomous driving, video surveillance, criminal investigation, etc.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_439",
                    "title": "Difficulties and Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_440",
                            "title": "Small pedestrian",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_441",
                                    "title": "the small pedestrians that are captured far from the camera.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_442",
                                    "title": "In Caltech Dataset, 15% of the pedestrians are less than 30 pixels in height.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_443",
                            "title": "Hard negatives",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_444",
                                    "title": "Some backgrounds in street view images are very similar to pedestrians in their visual appearance",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_445",
                            "title": "Dense and occluded pedestrian",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_446",
                                    "title": "In the Caltech Dataset , pedestrians that haven't been occluded only account for 29% of the total pedestrian instances.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_447",
                            "title": "Real-time detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_448",
                                    "title": "The real-time pedestrian detectionfrom HD video is crucial for some applications like autonomous driving and video surveillance.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_449",
                    "title": "Literature Review",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_450",
                            "title": "Traditional pedestrian detection methods",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_451",
                                    "title": "the Haar wavelet feature has been broadly used in early time\u2019s pedestrian detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_452",
                                    "title": "one popular idea of that time was \"detection by components\"",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_453",
                                    "title": "trained individually on different human parts,",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_454",
                                    "title": "since 2005, gradient-based representation and DPM have become the mainstream of pedes-trian detection.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_455",
                                    "title": "In 2009, by using the integral image acceleration, an effective and lightweight feature representation: the Integral Channel Features (ICF)",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_456",
                                    "title": "some domain knowledge also has been considered, such asappearance constancy and shape symmetry and stereo information",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_457",
                            "title": "Deep learning based pedestrian detection methods",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_458",
                                    "title": "To improve small pedestrian detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_459",
                                            "title": "Some recent solutions to this problem include featurefusion",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_460",
                                            "title": "introducing extra high-resolution handcraftedfeatures",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_461",
                                            "title": "ensembling detection results onmultiple resolutions",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_462",
                                    "title": "To improve hard negative detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_463",
                                            "title": "integration of boosted decision tree",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_464",
                                            "title": "semantics segmentation (as the context of thepedestrians)",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_465",
                                            "title": "the idea of \"cross-modallearning\" has also been introduced to enrich the feature of hard negatives by using both RGB and infrared images",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_466",
                                    "title": "To improve dense and occluded pedestrian detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_467",
                                            "title": "the features indeeper layers of CNN have richer semantics but are not effective for detecting dense objects.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_468",
                                            "title": "some researchers have designed new loss function by considering the attraction of target and the repulsion of other surrounding objects",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_469",
                                            "title": "Target occlusion is another problem that usually comes up with dense pedestrians.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_470",
                                            "title": "The ensemble ofpart detectors and the attention mechanism are the most common ways to improve occluded pedestrian detection",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_471",
            "title": "face detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_472",
                    "title": "\"smile\" detection in digital cameras, \"face swiping\" in e-commerce,facial makeup in mobile apps, etc.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_473",
                    "title": "Difficulties and Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_474",
                            "title": "Intra-class variation",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_475",
                                    "title": "Human faces may present a variety of expressions, skin colors, poses, and movements",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_476",
                            "title": "Occlusion",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_477",
                                    "title": "Faces may be partially occluded by other objects",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_478",
                            "title": "Multi-scale detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_479",
                                    "title": "Detecting faces in a large variety of scales, especially for some tiny faces",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_480",
                            "title": "Real-time detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_481",
                                    "title": "Face detection on mobile devices usually requires a CPU real-time detection speed.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_482",
                    "title": "Literature Review",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_483",
                            "title": "Early time's face detection (before 2001)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_484",
                                    "title": "Rule-based method",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_485",
                                            "title": "This group ofmethods encode human knowledge of what constitutes a typical face and capture the relationships between facial elements",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_486",
                                    "title": "Subspace analysis-based methods",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_487",
                                            "title": "This group of methods analyze the face distribution in underlying linear subspace",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_488",
                                            "title": "Eigenfaces is the representative of this group of methods",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_489",
                                    "title": "Learning basedmethods",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_490",
                                            "title": "to frame the face detection as a sliding window+ binary classification (target vs background) process.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_491",
                            "title": "Traditional face detection (2000-2015)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_492",
                                    "title": "First group of methods are built based on boosted decisiontrees",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_493",
                                            "title": "These methods are easy to compute, butusually suffer from low detection accuracy under complexscenes.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_494",
                                    "title": "The second group is based on early time\u2019s convolutional neural networks",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_495",
                                            "title": "where the shared computation of features are used to speed up detection",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_496",
                            "title": "Deep learning based face detection (after 2015)",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_497",
                                    "title": "To speed up face detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_498",
                                            "title": "Cascaded detection is the most common way tospeed up a face detector in deep learning era",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_499",
                                            "title": "Another speed up method is to predict the scale distributionof the faces in an image and then run detection on some selected scales",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                },
                                {
                                    "id": "line_500",
                                    "title": "To improve multi-pose and occluded face detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_501",
                                            "title": "The idea of \"face calibration\" has been used to improve multipose face detection by estimating the calibration parameters or using progressive calibration through multiple detection stages",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        },
                                        {
                                            "id": "line_502",
                                            "title": "improve occluded face detection",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_503",
                                                    "title": "attention mechanism",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_504",
                                                    "title": "detection based on parts",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "id": "line_505",
                                    "title": "To improve multi-scale face detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_506",
                                            "title": "multi-scale feature fusion and multi-resolution detection",
                                            "background-color": "#e3aba7",
                                            "collapsed": true
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_507",
            "title": "text detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_508",
                    "title": "to \"read\" street signs and currency",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_509",
                    "title": "In geographic information systems, the detectionand recognition of house numbers and street signs make iteasier to build digital maps",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_510",
                    "title": "Difficulties and Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_511",
                            "title": "Different fonts and languages",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_512",
                                    "title": "Texts may have differentfonts, colors, and languages",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_513",
                            "title": "Text rotation and perspective distortion",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_514",
                                    "title": "Texts mayhave different orientations and even may have perspective distortion",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_515",
                            "title": "Densely arranged text localization",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_516",
                                    "title": "Text lines with largeaspect ratios and dense layout are difficult to localize accu-rately",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_517",
                            "title": "Broken and blurred characters",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_518",
                                    "title": "Broken and blurredcharacters are common in street view images",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_519",
                    "title": "Literature Review",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_520",
                            "title": "Text detection consists of two related but relatively independent tasks",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_521",
                                    "title": "text localization",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_522",
                                    "title": "text recognition",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_523",
                            "title": "text detection methods can be divided into two groups",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_524",
                                    "title": "Step-wise detection vs integrated detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_525",
                                            "title": "Step-wise detection methods consist of a series of processing steps including character segmentation,candidate region verification, character grouping, and wordre cognition.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_526",
                                                    "title": "most of the background can be filtered in the coarse segmentationstep, which greatly reduces the computational cost of thefollowing process.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_527",
                                                    "title": "the parameters of all steps need to be set carefully, and the errors will occurand accumulate throughout each of these steps",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        },
                                        {
                                            "id": "line_528",
                                            "title": "the text detection as ajoint probability inference problem, where the steps of char-acter localization, grouping, and recognition are processedunder a unified framework.",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_529",
                                                    "title": "these methodsis it avoids the cumulative error and is easy to integrate language models.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_530",
                                                    "title": "inference will be computationally expensive when considering a largenumber of character classes and candidate windows",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "id": "line_531",
                                    "title": "Traditional methods vs deep learning methods",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_532",
                                            "title": "Most of the traditional text detection methods generatetext candidates in an unsupervised way",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_533",
                                                    "title": "the commonly used techniques include Maximally Stable ExtremalRegions (MSER) segmentation and morphological filtering",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_534",
                                                    "title": "the symmetry of texts and the structures of strokes, also have been considered in these methods",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_535",
                                                    "title": "researchers have paid more attention tothe problem of text localization rather than recognition",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true,
                                                    "children": [
                                                        {
                                                            "id": "line_536",
                                                            "title": "The first group ofmethods frame the text detection as a special case of generalobject detection",
                                                            "background-color": "#01a6d5",
                                                            "collapsed": true,
                                                            "children": [
                                                                {
                                                                    "id": "line_537",
                                                                    "title": "These methods have a unified detection framework, but it is less effective for detecting texts with orientation or with large aspect ratio.",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "id": "line_538",
                                                            "title": "The second group of methods frame the text detection as an image segmentation problem",
                                                            "background-color": "#01a6d5",
                                                            "collapsed": true,
                                                            "children": [
                                                                {
                                                                    "id": "line_539",
                                                                    "title": "The advantage of these methods is there are no special restrictions for the shape and orientation of text",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                },
                                                                {
                                                                    "id": "line_540",
                                                                    "title": "the disadvantage is that it is not easy to distinguish densely arranged text lines from each other based on the segmentation result.",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "id": "line_541",
                                                            "title": "For text rotation and perspective changes",
                                                            "background-color": "#01a6d5",
                                                            "collapsed": true,
                                                            "children": [
                                                                {
                                                                    "id": "line_542",
                                                                    "title": "The most common solution to this problem is to introduce additionalparameters in anchor boxes and RoI pooling layer that are associated with rotation and perspective changes",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "id": "line_543",
                                                            "title": "To improve densely arranged text detection",
                                                            "background-color": "#01a6d5",
                                                            "collapsed": true,
                                                            "children": [
                                                                {
                                                                    "id": "line_544",
                                                                    "title": "The segmentation-based approach shows more advantages indetecting densely arranged texts.",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                },
                                                                {
                                                                    "id": "line_545",
                                                                    "title": "To distinguish the adjacent text lines, two groups of solutions have been proposedrecently",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true,
                                                                    "children": [
                                                                        {
                                                                            "id": "line_546",
                                                                            "title": "segment and linking",
                                                                            "background-color": "#eb6a68",
                                                                            "collapsed": true,
                                                                            "children": [
                                                                                {
                                                                                    "id": "line_547",
                                                                                    "title": "\"segment\" refers to the character heatma",
                                                                                    "background-color": "#412ffc",
                                                                                    "collapsed": true
                                                                                },
                                                                                {
                                                                                    "id": "line_548",
                                                                                    "title": "\"linking\" refers to the connection between two adjacent segments indicating that they belong to the same word or line of text",
                                                                                    "background-color": "#412ffc",
                                                                                    "collapsed": true
                                                                                }
                                                                            ]
                                                                        },
                                                                        {
                                                                            "id": "line_549",
                                                                            "title": "additional corner/borderdetection",
                                                                            "background-color": "#eb6a68",
                                                                            "collapsed": true,
                                                                            "children": [
                                                                                {
                                                                                    "id": "line_550",
                                                                                    "title": "task to help separate densely arrange texts, where a group of corners or a closed boundary corresponds to an individual line of text",
                                                                                    "background-color": "#412ffc",
                                                                                    "collapsed": true
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "id": "line_551",
                                                            "title": "To improve broken and blurred text detection",
                                                            "background-color": "#01a6d5",
                                                            "collapsed": true,
                                                            "children": [
                                                                {
                                                                    "id": "line_552",
                                                                    "title": "A recent idea to deal with broken and blurred texts is to use word level recognition and sentence level recognition",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                },
                                                                {
                                                                    "id": "line_553",
                                                                    "title": "To deal with texts with different fonts, the mosteffective way is training with synthetic samples",
                                                                    "background-color": "#97d9c7",
                                                                    "collapsed": true
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_554",
            "title": "traffic sign/lightdetection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_555",
                    "title": "the automatic detection of traffic sign and traffic light has attracted great attention",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_556",
                    "title": "Difficulties and Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_557",
                            "title": "Illumination changes",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_558",
                                    "title": "The detection will be particularly difficult when driving into the sun glare or at night",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_559",
                            "title": "Motion blur",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_560",
                                    "title": "The image captured by an on-board camera will become blurred due to the motion of the car",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_561",
                            "title": "Bad weather",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_562",
                                    "title": "In bad weathers, e.g., rainy and snowy days, the image quality will be affected",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_563",
                            "title": "Real-time detection",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_564",
                                    "title": "This is particularly important for autonomous driving",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_565",
                    "title": "Literature Review",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_566",
                            "title": "Traditional detection methods",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_567",
                                    "title": "the traditionaldetection methods are usually based on color thresholding, visual saliency detection,morphological filtering and edge/contour analysis.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_568",
                                    "title": "they usually fail under complex environments",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_569",
                                    "title": "vision-based approaches, e.g.,to combine GPS and digital maps in traffic light detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_570",
                            "title": "deep learning based detection methods.",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_571",
                                    "title": "In deep learning era, some well-known detectors suchas Faster RCNN and SSD were applied in traffic sign/lightdetection tasks",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_572",
                                    "title": "On basis on these detectors,some new techniques, such as the attention mechanism andadversarial training have been used to improve detectionunder complex traffic environments",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_573",
            "title": "remote sensing/target detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_574",
                    "title": "emotesensing target detection (e.g., the detection of airplane, ship,oil-pot, etc), has become a research hot-spot. Remote sensingtarget detection has broad applications",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_575",
                    "title": "Difficulties and Challenges",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_576",
                            "title": "Detection in \"big data\"",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_577",
                                    "title": "Due to the huge data volumeof remote sensing images, how to quickly and accuratelydetect remote sensing targets remains a problem",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_578",
                            "title": "Occluded targets",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_579",
                                    "title": "Over 50% of the earth\u2019s surface is covered by cloud every day.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        },
                        {
                            "id": "line_580",
                            "title": "Domain adaptation",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_581",
                                    "title": "Remote sensing images capturedby different sensors present a high degree of differences.",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "line_582",
                    "title": "Literature Review",
                    "background-color": "#e3aba7",
                    "collapsed": false,
                    "children": [
                        {
                            "id": "line_583",
                            "title": "Traditional detection methods",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_584",
                                    "title": "traditional remote sensing target detection methods follow a two-stage detection paradigm",
                                    "background-color": "#0fbdff",
                                    "collapsed": true,
                                    "children": [
                                        {
                                            "id": "line_585",
                                            "title": "candidate extraction",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_586",
                                                    "title": "some frequently used methods include gray value filtering based methods , visual saliency-based methods , wavelet transform based methods, anomaly detection based methods , etc.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_587",
                                                    "title": "Onesimilarity of the above methods is they are all unsupervised methods, thus usually fail in complex environments.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        },
                                        {
                                            "id": "line_588",
                                            "title": "target verification",
                                            "background-color": "#e3aba7",
                                            "collapsed": true,
                                            "children": [
                                                {
                                                    "id": "line_589",
                                                    "title": "some frequently used features include HOG , LBP , SIFT , etc.",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_590",
                                                    "title": "To improve the occluded target detection, one commonly used idea is \"detection by parts\"",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                },
                                                {
                                                    "id": "line_591",
                                                    "title": "To detect targets with different orientations, the \"mixture model\" is used by training different detectors fortargets of different orientations",
                                                    "background-color": "#d41dea",
                                                    "collapsed": true
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "id": "line_592",
                            "title": "Deep learning based detection methods",
                            "background-color": "#e82ad2",
                            "collapsed": true,
                            "children": [
                                {
                                    "id": "line_593",
                                    "title": "After the great success of RCNN in 2014, deep CNN hasbeen soon applied to remote sensing target detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_594",
                                    "title": "The general object detection framework like Faster RCNN and SSD have attracted increasing attention inremote sensing community [",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_595",
                                    "title": "the deep CNN is no better than traditional methods for spectral data",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_596",
                                    "title": "To detect targets with different orientations, some researchers have im-proved the ROI Pooling layer for better rotation invariance",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_597",
                                    "title": "To improve domain adaptation, some researchers formulated the detection from a Bayesian view that at the detection stage, the model is adaptively updated based onthe distribution of test images",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                },
                                {
                                    "id": "line_598",
                                    "title": "the attention mechanisms and feature fusion strategy also have been used to improve small target detection",
                                    "background-color": "#0fbdff",
                                    "collapsed": true
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "id": "line_599",
            "title": "CONCLUSION AND FUTURE DIRECTIONS",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_600",
            "title": "The future research of object detection may focus but isnot limited to the following aspects",
            "background-color": "#fff",
            "collapsed": false
        },
        {
            "id": "line_601",
            "title": "Lightweight object detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_602",
                    "title": "To speed up the detection algorithm so that it can run smoothly on mobile devices.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_603",
            "title": "Detection meets AutoML",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_604",
                    "title": "A future direction is to reduce human intervention when designing the detection model",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_605",
            "title": "Detection meets domain adaptation",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_606",
                    "title": "The training process of any target detector can be essentially considered as a likelihood estimation process under the assumption of independent and identically distributed (i.i.d.) data",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_607",
            "title": "Weakly supervised detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_608",
                    "title": "Developing weakly supervised detection techniques where the detectors areonly trained with image-level annotations, or partially withbounding box annotations is of great importance for reducing labor costs and improving detection flexibility.",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_609",
            "title": "Small object detection",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_610",
                    "title": "Some further directions may include the integration of the visual attention mechanisms and the design of high resolution lightweight networks",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_611",
            "title": "Detection in videos",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_612",
                    "title": "whilesimply ignores the correlations between videos frames. Improving detection by exploring the spatial and temporal correlation is an important research direction",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        },
        {
            "id": "line_613",
            "title": "Detection with information fusion",
            "background-color": "#fff",
            "collapsed": false,
            "children": [
                {
                    "id": "line_614",
                    "title": "Object detectionwith multiple sources/modalities of data,",
                    "background-color": "#e3aba7",
                    "collapsed": false
                },
                {
                    "id": "line_615",
                    "title": "Some open questions include: how to immigrate well-trained detectors to different modalities of data",
                    "background-color": "#e3aba7",
                    "collapsed": false
                }
            ]
        }
    ]
}